---
title: 提取污染观测数据
date: 2022-10-25 09:18:14
toc: true
tags: data analysis
categories:
  - python
excerpt: 提取污染观测数据
---

# 观测数据匹配到模式网格上

- ```site_to_grid.py```

```python
#!/home/xdxie/packages/miniconda/envs/atmos/bin/python
# -*- coding: utf-8 -*- 
#****************************************************************#
#>  average site data to model grid
#>  can be used to compare the spatial distribution of simulation
#>  author: xiaodong xie @ 2023-4
#****************************************************************#
from math import radians,sin,cos,asin,sqrt
import xarray as xr
import pandas as pd
import numpy as np
#****************************************************************************************************#
# user config
year = 2016
stime = "2016-12-11 00:00:00"
etime = "2016-12-19 23:00:00"
GeoFile = "/r008/xdxie/data/wrfchemdata/beijing201612/presource/domain/geo_em.d02.nc"
OutFile = "/r008/xdxie/data/wrfchemdata/beijing201612/observation/obs.d02.timemean_20161211-1219.csv"
inpdatadir = '/r008/xdxie/data/obs/airquality'
#****************************************************************************************************#
f = xr.open_dataset(GeoFile)
lat2d = f['XLAT_M'].sel(Time=0)
lon2d = f['XLONG_M'].sel(Time=0)
allsite = pd.read_csv(f"{inpdatadir}/obssiteinfo.csv",encoding='gbk')

def haversine_dis(lon1, lat1, lon2, lat2):
    #将十进制转为弧度
    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])
    #haversine公式
    d_lon = lon2 - lon1
    d_lat = lat2 - lat1
    aa = sin(d_lat/2)**2 + cos(lat1)*cos(lat2)*sin(d_lon/2)**2
    c = 2 * asin(sqrt(aa))
    r = 6371 # 地球半径，千米
    return c*r*1000

def findij(latlon):
    a = abs(lat2d-latlon['lat'])+abs(lon2d-latlon['lon'])
    i,j = np.unravel_index(a.argmin(),a.shape)
    if (haversine_dis(lon2d[i,j], lat2d[i,j], latlon['lon'], latlon['lat']) > f.DX):
        return np.nan
    else:
        return [i,j]

def read_station_hourly_data(StationCode, year, stime, etime):
    temp = allsite.query("StationCode == @StationCode")
    ProvinceCode  = temp.ProvinceCode.values[0]
    CityCode = temp.CityCode.values[0]
    df = pd.read_csv(f"{inpdatadir}/QC+PPB/hour/{year}/{ProvinceCode}_{CityCode}_{StationCode}_{year}.csv",
                           index_col="datetime")
    df.index = pd.to_datetime(df.index,format="%Y-%m-%d %H:%M:%S")
    return df.loc[stime:etime]

latlons = allsite.loc[:,['lat','lon']]
a = latlons.apply(findij,axis=1)
a.name = "ij"
subsite = pd.concat([allsite, a], axis=1).dropna(subset=['ij'])

dfs = pd.DataFrame(columns=["station",'ix','jx','pm25', 'pm10', 'o3', 'co', 'so2', 'no2'])

for StationCode,ij in zip(subsite.StationCode,subsite.ij):
    temp = read_station_hourly_data(StationCode, year, stime, etime).mean()
    
    dfs = pd.concat([dfs,pd.DataFrame.from_records([{"station":f"{ij[0]}_{ij[1]}",
                                                     'ix':ij[0],
                                                     'jx':ij[1],
                                                     'pm25':temp.pm25,
                                                     'pm10':temp.pm10,
                                                     'o3':temp.o3,
                                                     'co':temp.co,
                                                     'so2':temp.so2,
                                                     'no2':temp.no2
                                              }])])
dfs.groupby("station").mean().to_csv(OutFile)

```

